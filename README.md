### **1. LLM Basics**

**1.1 Tokenization**
*  **Word-based tokenization**
*  **Character-based tokenization**
*  **Subword-based tokenization**
    *  **BPE (Byte-Pair Encoding)**
    *  **BBPE (Byte-level BPE)**
    *  **WordPiece**
    *  **Unigram**
    *  **SentencePiece**
 
**1.2 Embedding**

**1.2.1 History**
*  **One-hot Encoding**
*  **Co-occurrence Matrix**
*  **Distributed Word Representation**

**1.2.2 Static Embeddings**
*  **Word2Vec**
    *  **CBOW (Continuous Bag of Words)**
    *  **Skip-gram**
*  **GloVe (Global Vectors)**
*  **FastText**

**1.2.3 Contextual Embeddings**
